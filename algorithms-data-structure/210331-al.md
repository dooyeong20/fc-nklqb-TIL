# 이전 강의

- In-place 알고리즘 : O(logN) 보다 작은 공간 복잡도
  - swap만으로 되면 in-place가 됨
  - 만약에 공간을 할당해야하면 in-place가 안된다(merge sort)
- Stable 알고리즘 : 기존의 순서가 유지 되는 것(기준이 여러개 있을 때)

- 버블 소트
  - `swaped = False` 는 매우 중요한 최적화 요소이다
- 삽입 정렬(insertion sort)
  - 넣을 자리를 찾아가는 과정 + 찾으면 그 자리에 삽입

# 선택 정렬(selection sort)

버블 소트를 거꾸로 해놓은것과 비슷하게 보임  
하지만 버블 소트는 인접한 것끼리 비교당하면서 밀려서 끝으로 가는데, 선택정렬은 리스트의 최소 값을 찾아 맨 앞과 교체

- 버블소트보다 swap 이 더 적게 일어남
- 형식적으로보면 재귀적(?)
- 얘도 in-place임

## 시간 복잡도

- 최선, 최악, 평균 : 모두 O(n^2)
- 최선의 경우에는 시간복잡도는 그대로지만, swap연산이 일어나지 않을 수는 있음

```python
def selection_sort(x):
    length = len(x)
    for i in range(length-1):
        index_min = i
        for j in range(i+1, length):
            if x[index_min] > x[j]:
                index_min = j
        x[i], x[index_min] = x[index_min], x[i]
    return x
```

# 머지 소트

머지 소트를 응용하는 하이브리드 개념의 소팅에 많이 쓰인다

- 속도가 빠름에도 불구하고 `Stable` 알고리즘이다
- 비교가 O(logN)만큼 진행된다

## 머지 소트 알고리즘

- 정렬되지 않은 리스트는 두 부분(n 부분) 리스트로 나눔
  - 길이가 (0이나) 1인 경우는 정렬된 1짜리 리스트로 본다
- 나눠진 부분 리스트들을 합병해나가며 정렬된 임시 배열에 저장
  - 정렬한 리스트들을 저장할 공간이 필요한 이유는, 이미 있는 공간에 덮어써버리면 안되기 때문
- 재귀 구현하기 적합함
- 공간 복잡도: O(n) !!
- 시간 복잡도: O(nlogn)
  - 나눌 때 log(n)
  - 합병할 때(비교할 때) n

# 퀵 소트(Quick Sort)

핵심은 `pivot` !!

- 하나의 `pivot`(아무거나 선택 가능)을 선택해 이를 기준으로 작은 값을 좌측, 큰 값을 우측에 배치함
- 좌측, 우측에 대해 재귀적으로 반복 진행

- 만약 운이 나빠서 이미 정렬된 상태에서, 가장 작은 값으로 `pivot`이 계속 선택된다면, selection sort와 같아지게 된다. (O(n^2))

- 공간복잡도: O(logN)이지만, 구현방법에 따라 O(1)로도 구현할 수 있다(?)

- 시간복잡도
  - 최선: O(nlogN)
  - 최악: O(n^2)
  - 평균: O(nlogN)

# 팀소트(Timsort)

엄청나게 유명한 하이브리드 알고리즘

- Java SE 7, Android, GNU Octave, Chrome V8, Swift, Rust, Python 등에 적용된 정렬 알고리즘

- Insertion Sort와 Merge Sort를 결합하여 만든 알고리즘
  작은 영역에 대해서 Insertion Sort를 수행하고, 이것을 Merge Sort하여 최적화

- Insertion 이 O(n^2)이긴 하지만, n이 작은 상태에서는 지역성의 특정을 가지기 때문에 n이 충분히 작을 때는 insertion sort를 사용

  - 지역성: memory cache hit가 많이 발생하는 것

- 공간복잡도 : O(n)
- 시간복잡도
  - 최악의 경우: O(nlogn)
  - 최선의 경우: O(n) (이미 정렬이 되어있는 경우 insertion sort가 O(n))
  - 평균적인 경우: O(nlogn)

# 재귀 호출

함수가 자기 자신을 구현

- 재귀는 무조건 iteration으로 바꿀 수 있다
- 재귀식은이라고도 부르고, 수열의 항 사이의 관계를 나타냄
- 수열을 n에 대한 식으로 표현하는 것을 '풀이한다'고 한다
- 탈출조건이 반드시, 무조건 필요하다
  - 탈출조건: 잘게 쪼개져서 풀 필요가 없을 때
  - trivial, tidious 하다 라고 표현함
- 점화식에 의거하여 재귀 호출을 수행
  - 입력 파라미터를 달리하여, 결국 탈출 조건에 도달

## top-down, bottom-up

- top-down: 큰 것부터 잘게 쪼개가며 해결하는 것
  - 작은 문제를 호출해가며(쪼개나가며) 작은 문제를 풀어 합쳐 올라감
- bottom-up: 작은 것부터 확장해나가는 것

  - 문제를 다 쪼개놓은 상태에서 맞춰 올라나감

- 작은 문제부터 푸는 것은 매한가지임

## 재귀 문제점

- 여러번 재귀 호출이 발생하는 경우, 기하급수적으로 호출 횟수가 증가한다.
- 함수 호출 스택(Function call stack)의 크기에 제한이 있어, 일정 횟수 이상 호출이 불가하다.
- 실질적인 계산에 필요한 연산보다, 함수 호출에 의한 Overhead가 발생한다.

그래서 예를 들어 피보나치 수를 bottom-up으로 구현하면 종료조건 대신 초깃값을 설정해주면서 시작한다

```python
def fibonacci(n):
    fn_1, fn = 0, 1  # 초기값 설정

    if n == 0:
        return fn_1
    if n == 1:
        return fn

    for i in range(2, n + 1):  # 반복문 구현
        fn_1, fn = fn, fn_1 + fn

    return fn
```

## Tail Recursion

재귀 함수에서, 재귀 호출이 마지막에 딱 한번만 수행되는 것

- 컴파일러에서 최적화를 지원하면, 함수 호출 스택을 낭비하지 않는다
  - python은 지원하지 않는
- 함수 호출 스택을 재활용

예시

```python
# 재귀 최적화
def fibonacci(n, a=0, b=1):
    if n == 0:
        return a
    if n == 1:
        return b

    return fibonacci(n-1, b, a+b)

# 일반적 재귀
def fibonacci(n):
  if n == 0:
    return 0

  if n == 1:
    return 1

  return fibonacci(n-1) + fibonacci(n-2)
```
